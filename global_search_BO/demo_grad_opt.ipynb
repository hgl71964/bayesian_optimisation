{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch as tr\n",
    "\n",
    "# import scripts\n",
    "from src.grad_opt import random_opt\n",
    "from src.grad_opt import ADAM_opt\n",
    "from src.api_helper import api_utils\n",
    "from src.api_helper import env\n",
    "from datetime import datetime as dt, date as dt_date\n",
    "\n",
    "device = tr.device(\"cpu\")\n",
    "dtype = tr.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "init query tensor([[0.6845, 0.7377]])\ninit reward tensor([[-1.]]), origin reward: 7.34\n"
     ]
    }
   ],
   "source": [
    "@api_utils.multi_thread_transform\n",
    "def api(query): return env.rosenbrock(query)  # computation on cpu\n",
    "\n",
    "x0, y0 = tr.rand(2).view(1, -1), tr.tensor([[-1]], dtype=dtype).view(-1, 1)  \n",
    "r0 = env.rosenbrock(x0)  # initial reward on which normalisation based\n",
    "\n",
    "x0, y0= x0.to(device), y0.to(device)  # data in GPU\n",
    "\n",
    "print(\"init query\", x0); print(f\"init reward {api(x0, r0, device)}, origin reward: {r0.item():.2f}\")  # x,y stay on GPU while r0 in cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "T = 10  # total number of iterations\n",
    "\n",
    "# gp; includes \"MA2.5\", \"SE\", \"RQ\", \"LR\", \"PO\"\n",
    "gp_name, gp_params = \"MA2.5\",{\n",
    "                          \"mode\": \"raw\",      # \"raw\", \"add\", \"pro\" for GPs\n",
    "                          \"opt\":\"ADAM\",  # opt for MLE; (quasi_newton, ADAM)\n",
    "                          \"epochs\":128,       # epoch to run, if chosen ADAM\n",
    "                          \"lr\":1e-1,          # learning rate for ADAM\n",
    "                         }\n",
    "# q-parallelism (if use analytical acq_func, q must be 1)\n",
    "batch_size = 2\n",
    "\n",
    "acq_params = { \n",
    "    \"acq_name\" : \"qUCB\",          # acqu func; includes: \"EI\", \"UCB\", \"qEI\", \"qUCB\", \"qKG\"\n",
    "    \"N_start\": 32,               # number of starts for multi-start SGA\n",
    "    \"raw_samples\" :512,          # heuristic initialisation \n",
    "    \"N_MC_sample\" : 256,         # number of samples for Monte Carlo simulation\n",
    "    \"num_fantasies\": 128,        # number of fantasies used by KG\n",
    "    \"beta\":1.,                   # used by UCB/qUCB\n",
    "               }\n",
    "\n",
    "bayes_opt = bayesian_optimiser(gp_name, gp_params, device, acq_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NLML: -3.57\n",
      "Iter: 1, reward: -1,433.98\n",
      "NLML: 158,658,896.00\n",
      "Iter: 2, reward: -18.10\n",
      "NLML: 2,119,508.00\n",
      "Iter: 3, reward: -3.37\n",
      "NLML: 559,796.44\n",
      "Iter: 4, reward: -0.55\n",
      "NLML: 150,972.84\n",
      "Iter: 5, reward: -0.62\n",
      "NLML: 66,763.80\n",
      "Iter: 6, reward: -1.30\n",
      "NLML: 37,455.06\n",
      "Iter: 7, reward: -1.08\n",
      "NLML: 37,780.32\n",
      "Iter: 8, reward: -0.79\n",
      "NLML: 26,172.46\n",
      "Iter: 9, reward: -2.92\n",
      "NLML: 19,244.47\n",
      "Iter: 10, reward: -0.52\n",
      "CPU times: user 10.4 s, sys: 20 s, total: 30.4 s\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs, ys = bayes_opt.outer_loop(T, (-4,4),x0, y0, r0, api, batch_size)  # maximising reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([41, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1343, -0.0838,  0.0417],\n",
       "        [-0.1287,  0.1849,  0.0273],\n",
       "        [-0.0723,  0.0195, -0.1490],\n",
       "        [-0.0205, -0.0235, -0.1410],\n",
       "        [-0.0352,  0.2006,  0.0150],\n",
       "        [-0.0510, -0.0499,  0.1254],\n",
       "        [-0.0097,  0.0156,  0.0414],\n",
       "        [ 0.1429, -0.0915,  0.1546],\n",
       "        [-0.0561,  0.0283, -0.2781],\n",
       "        [ 0.0464, -0.0231, -0.0728]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tr.normal(0, .1, (10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5207, 0.4921])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "a  = tr.rand(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = tr.rand(10,3)\n",
    "r = tr.ones(10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([5.0071, 4.8981, 4.7572])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "n.T@r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n.numpy()\n",
    "r = r.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([5.007118 , 4.8981338, 4.757227 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "np.dot(n.T,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}