{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2020 Summer internship\n",
    "\n",
    "implement botorch model, such that it can be used by BOtorch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import botorch\n",
    "import gpytorch\n",
    "\n",
    "class BOtorch_GP:\n",
    "    \"\"\"\n",
    "    data type assume torch.tensor.float()\n",
    "\n",
    "    can only apply to standard kernels GPs\n",
    "    \"\"\"\n",
    "    def __init__(self,gp_name,**kwargs):\n",
    "        self.name = gp_name\n",
    "        self.params = kwargs\n",
    "\n",
    "    def init_model(self, x, y, state_dict=None):\n",
    "        \"\"\"\n",
    "        this implementation of zero-noise GP is more numerically robust;\n",
    "            initialise and update a BOtorch model every outside loop\n",
    "\n",
    "        Args:\n",
    "            x: training samples; shape [n, d] -> n samples, d-dimensional\n",
    "            y: function values; shape [n,m] -> multi-output m-dimensional; m = 1 in our case\n",
    "            state_dict: update model when it is provided\n",
    "\n",
    "        Returns:\n",
    "            mll: Gpytorch Marginal likelihood\n",
    "            model: Botorch model\n",
    "        \"\"\"\n",
    "        # zeros-noise settings\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        likelihood.noise = 1e-4  \n",
    "        likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
    "\n",
    "        model = botorch.models.SingleTaskGP(x, y, likelihood)\n",
    "\n",
    "        kernel = self.make_kernel(self.name)\n",
    "\n",
    "        if self.params[\"mode\"] == \"raw\":\n",
    "            model.covar_module = kernel\n",
    "        elif self.params[\"mode\"] == \"add\":\n",
    "            model.covar_module = gpytorch.kernels.AdditiveStructureKernel(base_kernel = kernel, num_dims = x.size(-1))\n",
    "        elif self.params[\"mode\"] == \"pro\":\n",
    "            model.covar_module = gpytorch.kernels.ProductStructureKernel(base_kernel = kernel, num_dims = x.size(-1))\n",
    "\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        if state_dict is not None:\n",
    "            model.load_state_dict(state_dict)\n",
    "        return mll, model\n",
    "\n",
    "    def fit_model(self, mll, model, x, y):\n",
    "        \"\"\"\n",
    "        MLE tuning via ADAM\n",
    "        Args:\n",
    "            x -> shape[n,d]; tensor\n",
    "            y -> shape[n,1]; tensor\n",
    "        \"\"\"\n",
    "        if self.params[\"opt\"] == \"ADAM\":\n",
    "            self._ADAM(mll,model,x,y)\n",
    "        elif self.params[\"opt\"] == \"quasi_newton\":\n",
    "            self._quasi_newton(mll)\n",
    "    \n",
    "    def make_kernel(self, name):\n",
    "        if name == \"SE\":\n",
    "            kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        elif name == \"RQ\":\n",
    "            kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RQKernel())\n",
    "        elif name == \"MA2.5\":\n",
    "            kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5))\n",
    "        elif name == \"PO2\":\n",
    "            kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PolynomialKernel(power = 2))\n",
    "        elif name == \"PO3\":\n",
    "            kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PolynomialKernel(power = 3))\n",
    "        elif name == \"LR\":\n",
    "            kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel())\n",
    "        return kernel\n",
    "\n",
    "    def _ADAM(self, mll,model,x,y):\n",
    "        \"\"\"\n",
    "        MLE tuning via ADAM\n",
    "        Args:\n",
    "            x -> shape[n,d]; tensor\n",
    "            y -> shape[n,1]; tensor\n",
    "        \"\"\"\n",
    "        # when training: y -> shape[n,]\n",
    "        y  = y.squeeze(-1)\n",
    "\n",
    "        model.train()\n",
    "        model.likelihood.train()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.params[\"lr\"])\n",
    "\n",
    "        for _ in range(self.params[\"epochs\"]):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = -mll(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Iter %d - Loss: %.3f\" % (self.params[\"epochs\"], loss.item()))\n",
    "        model.eval()\n",
    "        model.likelihood.eval()\n",
    "\n",
    "    def _quasi_newton(self, mll):\n",
    "        \"\"\"\n",
    "        MLE tuning via L-BFGS-B\n",
    "        mll: marginal likelihood of model; work for BOtorch and Gpytorch model\n",
    "\n",
    "        but this cannot handle SM kernel\n",
    "        \"\"\"\n",
    "        botorch.fit_gpytorch_model(mll)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "# def init_model(self, x, y, state_dict=None):\n",
    "    #     \"\"\"\n",
    "    #     initialise and update a BOtorch model every outside loop\n",
    "\n",
    "    #     Args:\n",
    "    #         x: training samples; shape [n, d] -> n samples, d-dimensional\n",
    "    #         y: function values; shape [n,m] -> multi-output m-dimensional; m = 1 in our case\n",
    "    #         state_dict: update model when it is provided\n",
    "\n",
    "    #     Returns:\n",
    "    #         mll: Gpytorch Marginal likelihood\n",
    "    #         model: Botorch model\n",
    "    #     \"\"\"\n",
    "    #     # make noise; we have zero noise\n",
    "    #     noise = torch.zeros_like(y, dtype = y.dtype)\n",
    "\n",
    "    #     model = botorch.models.FixedNoiseGP(x, y, noise)\n",
    "    #     model.covar_module = eval(\"self._\"+f\"{self.name}()\")\n",
    "    #     model.likelihood.learn_additional_noise = False\n",
    "\n",
    "    #     mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    #     if state_dict is not None:\n",
    "    #         model.load_state_dict(state_dict)\n",
    "    #     return mll, model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
